{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "integrated-relay",
   "metadata": {},
   "source": [
    "# Analyzing representative cycles for persitent homology with Giotto-TDA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "operational-richmond",
   "metadata": {},
   "source": [
    "The goal of this notebook is to interpret the cycle information for persistent homology. \n",
    "\n",
    "We investigate the cycle information of the persistent homology on a subset of MNIST dastaset, and study the possible applications from the direct visualization of the cycle information."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "metric-solution",
   "metadata": {},
   "source": [
    "# 1. Introduction and Motivation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "oriental-reality",
   "metadata": {},
   "source": [
    "Information captured by persistent homology is commonly represented by a persistence diagram or, equivalently, a persistence barcode. \n",
    "\n",
    "These are elegant mathematical representations of the homology classes that appear and disappear in a filtration. However, their use for exploratory data analysis is challenging. While they effectively represent the lifespan of each homology class, they also lose connection with the original domain of data.  \n",
    "\n",
    "This brings to two main problems:\n",
    "\n",
    "1. we have no information regarding the distribution of persistence pairs in the original domain\n",
    "2. we have no information regarding the shape of each homology class appearing in the filtration.\n",
    "\n",
    "This means that interpreting the results becomes extremely difficult for a user. Experts in TDA may be able to guess this information by combaning persistence diagrams with a visualization of the original filtration. However, this is generally not an easy task, especially for newcomers. \n",
    "\n",
    "Questions like\n",
    "\n",
    "- Is the filtration I am using correct?\n",
    "- Are the homology classes appearing in my persistence diagram aligned with the features I see in the input data?\n",
    "\n",
    "are quite natural when we start computing persistent homology on a new dataset. \n",
    "\n",
    "\n",
    "To be able to answer this type of questions we need to map information from the persistence diagram back to the original domain of the filtration. In this notebook, we provide a collection of functions to simplify the interactive visualization and analysis of homology class by enriching the information contained in the persistence diagram with cycles."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pretty-convertible",
   "metadata": {},
   "source": [
    "# 2. Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "owned-springfield",
   "metadata": {},
   "source": [
    "## 2.1. Dataset description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legendary-ukraine",
   "metadata": {},
   "source": [
    "![dataset](./pictures/dataset.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-confidentiality",
   "metadata": {},
   "source": [
    "In the remainder of this notebook, we use a sample of the original MNIST dataset downloaded from [here](http://yann.lecun.com/exdb/mnist/). The dataset provided in this submission includes 500 handwritten digits (50 images per digit) that have been size-normalized and centered in a fixed-size image.\n",
    "\n",
    "\n",
    "## 2.2. Preprocessing\n",
    "\n",
    "The first step when using persistent homology is that of defining a filtration on the input data. This already provides a degree of freedom for users that may define the most suitable filtration based on the features they want to be highlighted.\n",
    "\n",
    "For example, in the case of an MNIST digit we may want to highlight dominant cycles in the input digits. To this end, we may use different filtrations:\n",
    "- the one defined by the original grayscale image, \n",
    "- the inverse(negated) grayscale image,\n",
    "- or new image obtained by applying the distance transform to the input image\n",
    "\n",
    "to name a few. Clearly, each image will be transformed in a filtration generating different homology cycles and, consequently, different persistence diagrams. In this notebook, all filtrations are generated applying the distance transform to the input image, but any other filtration could be used instead."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "analyzed-allowance",
   "metadata": {},
   "source": [
    "![filtrations](pictures/filtrations.png)\n",
    "Images generated with `./scripts/filtrations.py`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cross-infrared",
   "metadata": {},
   "source": [
    "### External tools\n",
    "\n",
    "The computation of persistence diagrams and representative cycles has been implemented in a plain C++ [library](https://github.com/IuricichF/PersistenceCycles) integrated in the Topology Toolkit (TTK) [TTK](https://topology-tool-kit.github.io). For simplicity, we have precomputed all persitence diagrams and all representative cycles with our external library and saved them in the folder `data/vtk-*/`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eleven-donor",
   "metadata": {},
   "source": [
    "## 2.3. Visualizying cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "identical-aaron",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "# Check Python version and make sure the version >= 3.8.0 \n",
    "print(sys.version)\n",
    "\n",
    "# Install dependencies \n",
    "!{sys.executable} -m pip install meshio\n",
    "!{sys.executable} -m pip install giotto-tda\n",
    "!{sys.executable} -m pip install scikit-image\n",
    "!{sys.executable} -m pip install pandas"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjusted-eugene",
   "metadata": {},
   "source": [
    "The functions provided in this notebook allow for the easy visualization and comparison of homology classes by means of the representative cycles.\n",
    "\n",
    "For each pair of dimension 1 in the persistence diagram, there is a 1-cycle representing the boundary of the corresponding homology class as appeared in the filtration. Persistence pairs and cycles can be accessed by reading the VTK files with `meshio`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "soviet-thinking",
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshio\n",
    "ppairs = meshio.read(\"./data/vtk-original/0/3_pd.vtk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "binding-maine",
   "metadata": {},
   "source": [
    "The persistence diagram is stored as a collection of lines. \n",
    "Each line represents a persistence pair. The line end-points are geometrically located where the homology class was born/died.\n",
    "\n",
    "For each line of index `i` we can access:\n",
    "- the persistence value associated with the pair (`ppairs.cell_data[\"Persistence\"][i]`)\n",
    "- the dimension of the homology class (`ppairs.cell_data[\"Type\"][i]`)\n",
    "- the end-points of the line (`ppairs.cells[0].data[i][0]`,`ppairs.cells[0].data[i][1]`)\n",
    "\n",
    "\n",
    "For each point of index `p` we can access:\n",
    "- the dimension of the corresponding simplex (`ppairs.point_data[\"Type\"][p]`)\n",
    "- the filtration value (`ppairs.point_data[\"Filtration\"][p]`)\n",
    "- the point position in the original domain (`ppairs.points[p]`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "least-breast",
   "metadata": {},
   "outputs": [],
   "source": [
    "import meshio\n",
    "cycle = meshio.read(\"./data/vtk-original/0/3_cycles.vtk\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exciting-arthur",
   "metadata": {},
   "source": [
    "Since we are analyzing 2D images, we only have 1-dimensional cycles to represent the homology class. Then, each cycle is stored as a collection of lines. \n",
    "\n",
    "For each line of index `i` we can access:\n",
    "- the unique id of the cycle this edge belongs to (`cycle.cell_data[\"CycleId\"][i]`). Moreover, the CycleID indicates the persistence pair corresponding to the cycle (`ppair.cell_data[cycle.cell_data[\"CycleId\"][i]]`) \n",
    "- the persistence value associated to the persistence pair (`cycle.cell_data[\"Filtration][i]`)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "great-grant",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import meshio\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import gtda.plotting as gplotting\n",
    "import gtda.diagrams as gdiagrams\n",
    "import plotly.express as px\n",
    "import plotly.graph_objs as gobj\n",
    "from plotly.offline import init_notebook_mode, iplot\n",
    "from skimage import io\n",
    "from scipy import ndimage\n",
    "\n",
    "\n",
    "DATA_DIR = os.path.join(os.getcwd(), \"data\")          # path of the data folder\n",
    "IMG_DIR = os.path.join(DATA_DIR, \"mnist_png\")         # path of the image folder\n",
    "VTK_DIR = os.path.join(DATA_DIR, \"vtk-distancetransform\")               # path of the vtk files originated with the distance transform\n",
    "\n",
    "init_notebook_mode()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "royal-edgar",
   "metadata": {},
   "source": [
    "We have defined a couple of helper functions that can be used to extract information from these files:\n",
    "- `getPersCycles()`: Extract information about the geometry of each cycle stored in a vtk file.\n",
    "- `getPersDiagram()`: Create a persistence diagram starting from the persistence pairs stoored in a vtk file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "straight-polls",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPersCycles(cycleFile):\n",
    "    \"\"\"\n",
    "    Get persistence cycles from the vtk file storing the persistence cycles.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    cycleFile: string\n",
    "        The path of the vtk file storing the persistence cycles.\n",
    "    \n",
    "    Returns\n",
    "    ---------\n",
    "    ordered_cycles: dict\n",
    "        The dictionary storing the cycle information.\n",
    "    \"\"\"\n",
    "    im = meshio.read(cycleFile)\n",
    "    \n",
    "    # for each cycle id, save the list of edges\n",
    "    ordered_cycles = {}\n",
    "    array_of_cycles = {}\n",
    "    for i in range(len(im.cell_data['CycleId'][0])):\n",
    "        index = str(im.cell_data['CycleId'][0][i])\n",
    "\n",
    "        if(index not in array_of_cycles):\n",
    "            array_of_cycles[index] = []\n",
    "\n",
    "\n",
    "        line = im.cells_dict['line'][i]\n",
    "        array_of_cycles[index].append([line[0].tolist(), line[1].tolist()])\n",
    "    \n",
    "    # inner function to search for the next point\n",
    "    def searchNext(all_lines, visited, point, prev):\n",
    "        for i in range(len(all_lines)):\n",
    "            if(not visited[i]):\n",
    "                line = all_lines[i]\n",
    "                if(point == line[0] and prev != line[1]):\n",
    "                    visited[i] = True\n",
    "                    return line[1]\n",
    "                elif(point == line[1] and prev != line[0]):\n",
    "                    visited[i] = True\n",
    "                    return line[0]\n",
    "        \n",
    "    # for each cycle reorder the vertices so to have them ready to be plotted with THREE.js\n",
    "    for k in array_of_cycles:\n",
    "        val = array_of_cycles[k]\n",
    "        visited = np.zeros(len(val))\n",
    "        new_array = []\n",
    "\n",
    "        first_point= val[0][0]\n",
    "        prevP = val[0][0]\n",
    "        nextP = val[0][1]\n",
    "\n",
    "        visited[0] = True\n",
    "\n",
    "        new_array.append(im.points[first_point].tolist())\n",
    "        while(nextP != first_point):\n",
    "            new_array.append(im.points[nextP].tolist())\n",
    "            newP = searchNext(val, visited, nextP, prevP)\n",
    "            prevP = nextP\n",
    "            nextP = newP\n",
    "\n",
    "        new_array.append(im.points[first_point].tolist())\n",
    "        ordered_cycles[k] = new_array\n",
    "        \n",
    "    return ordered_cycles    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "foreign-saskatchewan",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPersDiagram(diagramFile):\n",
    "    \"\"\"\n",
    "    Get persistence diagram pairs from the vtk file storing persistence diagram.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    diagramFile: string\n",
    "        The path of the diagram vtk file.\n",
    "        \n",
    "    Returns \n",
    "    ----------\n",
    "    pdiagram: array\n",
    "        The numpy array storing the persistence diagram in the form (birth, death, dimension).\n",
    "    \"\"\"\n",
    "    pdiagram = []\n",
    "    try: \n",
    "        ppairs = meshio.read(diagramFile)\n",
    "        k = 0\n",
    "        for line in ppairs.cells[0].data: \n",
    "            v0 = line[0]\n",
    "            v1 = line[1]\n",
    "            f0 = ppairs.point_data[\"Filtration\"][v0]    # birth\n",
    "            f1 = ppairs.point_data[\"Filtration\"][v1]    # death\n",
    "            t = ppairs.cell_data[\"Type\"][0][k]          # homology dimension\n",
    "            k += 1\n",
    "            # if t == 1: \n",
    "            pdiagram.append([f0, f1, t])\n",
    "    except:\n",
    "        print(\"No persistence pairs in the file\")\n",
    "    return np.asarray(pdiagram)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-vault",
   "metadata": {},
   "source": [
    "The plotting functions use the VTK files to produce visualization with Plotly.\n",
    "\n",
    "The first step is that of visualizing components and cycles alone. To do so, we have implemented two functions to overlay such information to the image of the digit used to generate them. The function uses the `Scatter` class form Plotly.\n",
    "\n",
    "The first function, `visualizeComponents`, simply reads the persistence pairs from the persistence diagram and plots them in the original image domain. For each point, it also indicates their lifespan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "refined-shopping",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeComponents(img, diagramFile):\n",
    "    \"\"\"\n",
    "        Plot persistence cycles on the original image file.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        img: matrix\n",
    "            The matrix storing the image. \n",
    "        diagramFile: string\n",
    "            The path of the vtk file storing the persistence pairs.\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        fig : :class:`plotly.graph_objects.Figure` object\n",
    "            Figure showing where each component was born.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = px.imshow(img, color_continuous_scale='gray')\n",
    "\n",
    "        \n",
    "    ppairs = meshio.read(diagramFile)\n",
    "    k = 0\n",
    "    xcoords = []\n",
    "    ycoords = []\n",
    "    births = []\n",
    "    deaths = []\n",
    "    for line in ppairs.cells[0].data: \n",
    "        if(ppairs.cell_data[\"Type\"][0][k] == 0):\n",
    "            xcoords.append(ppairs.points[line[0]][1])\n",
    "            ycoords.append(ppairs.points[line[0]][0])\n",
    "            births.append(ppairs.point_data[\"Filtration\"][line[0]])\n",
    "            deaths.append(ppairs.point_data[\"Filtration\"][line[1]])\n",
    "    \n",
    "    \n",
    "    df = pd.DataFrame(data={\"x\":xcoords, \"y\":ycoords, \"birth\":births, \"death\":deaths})\n",
    "    fig.add_trace(gobj.Scatter(x=df[\"x\"], y=df[\"y\"], text=df[\"death\"]-df[\"birth\"], hoverinfo=\"text\", mode=\"markers\"))\n",
    "    \n",
    "    \n",
    "    head_tail = os.path.split(diagramFile)\n",
    "    digit = head_tail[0][-1]\n",
    "    filename = head_tail[1]\n",
    "    fig.update_layout(height=400, width=400, title_text=\"Digit \"+digit+\" - Persistence Diagram file \"+filename)\n",
    "    fig.update_layout(coloraxis_showscale=False)\n",
    "    fig.update_xaxes(showticklabels=False)\n",
    "    fig.update_yaxes(showticklabels=False)\n",
    "        \n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sporting-aquatic",
   "metadata": {},
   "source": [
    "With `visualizeComponets` we can plot components overlayed to the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "unique-command",
   "metadata": {},
   "outputs": [],
   "source": [
    "digitPrefix = \"0/10\"\n",
    "pngFile = os.path.join(IMG_DIR, digitPrefix+\".png\")\n",
    "img = io.imread(pngFile)\n",
    "\n",
    "diagramFile = os.path.join(VTK_DIR, digitPrefix+\"_pd.vtk\")\n",
    "\n",
    "visualizeComponents(img,diagramFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "congressional-jumping",
   "metadata": {},
   "source": [
    "or overlayed to filtration that originated the persistence pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "wooden-fisher",
   "metadata": {},
   "outputs": [],
   "source": [
    "digitPrefix = \"0/10\"\n",
    "pngFile = os.path.join(IMG_DIR, digitPrefix+\".png\")\n",
    "im = io.imread(pngFile)\n",
    "\n",
    "inside = im > 0\n",
    "outside = im <= 0\n",
    "\n",
    "im1 = ndimage.morphology.distance_transform_edt(inside)\n",
    "im2 = ndimage.morphology.distance_transform_edt(outside)\n",
    "\n",
    "imf = im2-im1\n",
    "imf = (imf - np.min(imf))/np.ptp(imf)\n",
    "\n",
    "cycleFile = os.path.join(VTK_DIR, digitPrefix+\"_pd.vtk\")\n",
    "visualizeComponents(imf, cycleFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "imported-blood",
   "metadata": {},
   "source": [
    "The second function, `visualizeCycles`, uses a helper function `getPersCycles` to read the ordered sequence of vertices forming each cycle."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "magnetic-combat",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualizeCycles(img, cycleFile):\n",
    "    \"\"\"\n",
    "    Plot persistence cycles on the original image file.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    img: matrix\n",
    "        The matrix storing the image. \n",
    "    cycleFile: string\n",
    "        The path of the vtk file storing the persistence cycles.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    fig : :class:`plotly.graph_objects.Figure` object\n",
    "        Figure showing the persistence cycles on top of the image file.\n",
    "    \"\"\"\n",
    "    \n",
    "    fig = px.imshow(img, color_continuous_scale='gray')\n",
    "    \n",
    "    try: \n",
    "        ordered_cycles = getPersCycles(cycleFile)\n",
    "        coords = list(ordered_cycles.values())\n",
    "        for cycle in coords:        \n",
    "            flat_coords = np.asarray([item for item in cycle])\n",
    "            fig.add_trace(gobj.Scatter(x=flat_coords[:,1], y=flat_coords[:,0], mode='lines'))\n",
    "\n",
    "        # Adjust the properties of the figure\n",
    "        head_tail = os.path.split(cycleFile)\n",
    "        digit = head_tail[0][-1]\n",
    "        filename = head_tail[1]\n",
    "        fig.update_layout(height=400, width=400, title_text=\"Digit \"+digit+\" - Cycle file \"+filename)\n",
    "        fig.update_layout(coloraxis_showscale=False)\n",
    "        fig.update_xaxes(showticklabels=False)\n",
    "        fig.update_yaxes(showticklabels=False)\n",
    "        \n",
    "    except:\n",
    "        print(\"No cycles to visualize\")\n",
    "    \n",
    "    return fig\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "electronic-swing",
   "metadata": {},
   "source": [
    "Also in this case, `visualizeCycles` accepts an image as input. This can be used to visualize cycles overlayed to the original image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "loving-reset",
   "metadata": {},
   "outputs": [],
   "source": [
    "digitPrefix = \"8/110\"\n",
    "pngFile = os.path.join(IMG_DIR, digitPrefix+\".png\")\n",
    "img = io.imread(pngFile)\n",
    "\n",
    "cycleFile = os.path.join(VTK_DIR, digitPrefix+\"_cycles.vtk\")\n",
    "\n",
    "\n",
    "visualizeCycles(img, cycleFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parliamentary-application",
   "metadata": {},
   "source": [
    "or overlayed to the filtration that originated the cycles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "characteristic-civilian",
   "metadata": {},
   "outputs": [],
   "source": [
    "digitPrefix = \"8/110\"\n",
    "pngFile = os.path.join(IMG_DIR, digitPrefix+\".png\")\n",
    "im = io.imread(pngFile)\n",
    "\n",
    "inside = im > 0\n",
    "outside = im <= 0\n",
    "\n",
    "im1 = ndimage.morphology.distance_transform_edt(inside)\n",
    "im2 = ndimage.morphology.distance_transform_edt(outside)\n",
    "\n",
    "imf = im2-im1\n",
    "imf = (imf - np.min(imf))/np.ptp(imf)\n",
    "\n",
    "cycleFile = os.path.join(VTK_DIR, digitPrefix+\"_cycles.vtk\")\n",
    "visualizeCycles(imf, cycleFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "attached-advantage",
   "metadata": {},
   "source": [
    "# 2.4. Applications\n",
    "\n",
    "Here we provide two examples where the direct visualization of cycles can be of help.\n",
    "\n",
    "### Definition of the most suitable filtration\n",
    "\n",
    "The first scenario where the direct visualization of cycles could be useful is when we are deciding how to create a suitable filtration for the input data. In general, we would like to use the best filtration so to highlight/capture the main features of our input as persistence pairs. Different filtration will naturally lead to different features. The direct visualization of these features can help us in our choice.\n",
    "\n",
    "For example, using the MNIST dataset, we may decide to filter each input image according to the original pixel values, or the opposite order, or to use some other transformation (e.g., distance transform).\n",
    "\n",
    "![filtrations](pictures/filtrations.png)\n",
    "Images generated with `./scripts/filtrations.py`\n",
    "\n",
    "What filtration is the most suitable for our goal? We could better decide by looking at the features created.\n",
    "In this example we pick one of the files encoding a digit `8`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "owned-museum",
   "metadata": {},
   "outputs": [],
   "source": [
    "digitPrefix = \"8/110\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "potential-groove",
   "metadata": {},
   "source": [
    "Then select the original fitlration as defined by graylevel pixels values and we visualize the generated cycles."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranking-dutch",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "VTK_DIR_ORIG = os.path.join(DATA_DIR, \"vtk-original\") \n",
    "\n",
    "pngFile = os.path.join(IMG_DIR, digitPrefix+\".png\")\n",
    "img = io.imread(pngFile)\n",
    "cycleFile = os.path.join(VTK_DIR_ORIG, digitPrefix+\"_cycles.vtk\")\n",
    "\n",
    "visualizeCycles(img, cycleFile)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dressed-rebate",
   "metadata": {},
   "source": [
    "The same process is repeated negating the graylevel values of the input image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "known-consideration",
   "metadata": {},
   "outputs": [],
   "source": [
    "VTK_DIR_INV = os.path.join(DATA_DIR, \"vtk-inverse\")\n",
    "\n",
    "pngFile = os.path.join(IMG_DIR, digitPrefix+\".png\")\n",
    "img = io.imread(pngFile)\n",
    "cycleFile = os.path.join(VTK_DIR_INV, digitPrefix+\"_cycles.vtk\")\n",
    "\n",
    "visualizeCycles(img, cycleFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "proved-scanning",
   "metadata": {},
   "source": [
    "And finally using the distance transform."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "objective-solid",
   "metadata": {},
   "outputs": [],
   "source": [
    "pngFile = os.path.join(IMG_DIR, digitPrefix+\".png\")\n",
    "img = io.imread(pngFile)\n",
    "cycleFile = os.path.join(VTK_DIR, digitPrefix+\"_cycles.vtk\")\n",
    "\n",
    "visualizeCycles(img, cycleFile)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "anonymous-institute",
   "metadata": {},
   "source": [
    "As we can notice, the filtration based on the origina graylevel values is not necesseraly the one better highlighting the features of the input digit. In this case the filtration starts from the dark pixels thus creating a large cycle `trace 6` which is later broken in smaller parts as soon as the lighter pixels are introduced.\n",
    "\n",
    "The filtration based on the inverse of the of the graylevel values does a better job at localyzing the two loops in the `8` digit but many other cycles are created due to noise in the input image.\n",
    "\n",
    "The filtration based on the distance transform is similar to the previous but less noisy, and thus generates fewer cycles.\n",
    "\n",
    "\n",
    "Regardless of our final choice, the direct visualization of the cycles can help us deciding which one is the best filtration for the features we would like to recognize in our input data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "honest-support",
   "metadata": {},
   "source": [
    "### Unsupervised analysis with topological features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hearing-desperate",
   "metadata": {},
   "source": [
    "As an example where visualizing cycles could be of help, we consider the unsupervised analysis of data by means of TDA descriptors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "found-dinner",
   "metadata": {},
   "source": [
    "For each input image in the MNIST dataset we compute a descriptor by means of `PersistenceImages`. Persistence Images are computed using the function provided by [Giotto-tda](https://giotto-ai.github.io/gtda-docs/0.2.1/modules/generated/diagrams/representations/gtda.diagrams.PersistenceImage.html). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd642c06",
   "metadata": {},
   "source": [
    "Here we experienced some issue with getting the correct persistence image when there is only 1 persistence pair in the diagram. Based on the filtration we used in the previous step, we adapt the `_bin()` function from `gtda.diagrams._utils` by manually setting the minimum and maximum value. Since the function is called in `fit()` function of `PersistenceImage` class, we also create a variation of `fit()` function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "rural-butter",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gtda.diagrams._utils import _subdiagrams, _sample_image, _homology_dimensions_to_sorted_ints\n",
    "\n",
    "def bins(X, metric, n_bins=100, homology_dimensions=None, **kw_args):\n",
    "    if homology_dimensions is None:\n",
    "        homology_dimensions = sorted(np.unique(X[0, :, 2]))\n",
    "    # For some vectorizations, we force the values to be the same + widest\n",
    "    sub_diags = {dim: _subdiagrams(X, [dim], remove_dim=True)\n",
    "                 for dim in homology_dimensions}\n",
    "    # For persistence images, move into birth-persistence\n",
    "    if metric == 'persistence_image':\n",
    "        for dim in homology_dimensions:\n",
    "            sub_diags[dim][:, :, [1]] = sub_diags[dim][:, :, [1]] \\\n",
    "                - sub_diags[dim][:, :, [0]]\n",
    "    \n",
    "    min_vals = {dim: np.asarray([0, 0])\n",
    "                for dim in homology_dimensions}\n",
    "#     max_vals = {dim: np.asarray([1, 1])\n",
    "#                 for dim in homology_dimensions}\n",
    "    max_vals = {dim: np.max(sub_diags[dim], axis=(0, 1))\n",
    "                for dim in homology_dimensions}\n",
    "    \n",
    "    if metric in ['landscape', 'betti', 'heat', 'silhouette']:\n",
    "        #  Taking the min(resp. max) of a tuple `m` amounts to extracting\n",
    "        #  the birth (resp. death) value\n",
    "        min_vals = {d: np.array(2*[np.min(m)]) for d, m in min_vals.items()}\n",
    "        max_vals = {d: np.array(2*[np.max(m)]) for d, m in max_vals.items()}\n",
    "\n",
    "    # Scales between axes should be kept the same, but not between dimension\n",
    "    all_max_values = np.stack(list(max_vals.values()))\n",
    "    if len(homology_dimensions) == 1:\n",
    "        all_max_values = all_max_values.reshape(1, -1)\n",
    "    global_max_val = np.max(all_max_values, axis=0)\n",
    "    max_vals = {dim: np.array([max_vals[dim][k] if\n",
    "                               (max_vals[dim][k] != min_vals[dim][k])\n",
    "                               else global_max_val[k] for k in range(2)])\n",
    "                for dim in homology_dimensions}\n",
    "    \n",
    "    samplings = {}\n",
    "    step_sizes = {}\n",
    "    for dim in homology_dimensions:\n",
    "        samplings[dim], step_sizes[dim] = np.linspace(\n",
    "            min_vals[dim], max_vals[dim], retstep=True, num=n_bins)\n",
    "    if metric in ['landscape', 'betti', 'heat', 'silhouette']:\n",
    "        for dim in homology_dimensions:\n",
    "            samplings[dim] = samplings[dim][:, [0], None]\n",
    "            step_sizes[dim] = step_sizes[dim][0]\n",
    "    return samplings, step_sizes\n",
    "\n",
    "\n",
    "def fit(pimgObj, X):\n",
    "    if pimgObj.weight_function is None:\n",
    "        pimgObj.effective_weight_function_ = np.ones_like\n",
    "    else:\n",
    "        pimgObj.effective_weight_function_ = pimgObj.weight_function\n",
    "\n",
    "    # Find the unique homology dimensions in the 3D array X passed to `fit`\n",
    "    # assuming that they can all be found in its zero-th entry\n",
    "    homology_dimensions_fit = np.unique(X[0, :, 2])\n",
    "    pimgObj.homology_dimensions_ = \\\n",
    "        _homology_dimensions_to_sorted_ints(homology_dimensions_fit)\n",
    "    pimgObj._n_dimensions = len(pimgObj.homology_dimensions_)\n",
    "\n",
    "    pimgObj._samplings, pimgObj._step_size = bins(\n",
    "        X, \"persistence_image\",  n_bins=pimgObj.n_bins,\n",
    "        homology_dimensions=pimgObj.homology_dimensions_\n",
    "        )\n",
    "    pimgObj.weights_ = {\n",
    "        dim: pimgObj.effective_weight_function_(samplings_dim[:, 1])\n",
    "        for dim, samplings_dim in pimgObj._samplings.items()\n",
    "        }\n",
    "    pimgObj.samplings_ = {dim: s.T for dim, s in pimgObj._samplings.items()}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa8ea1e4",
   "metadata": {},
   "source": [
    "We now use the new functions to compute the persistence images for the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e488c80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def getPersImage(diagramFile, dimension=None, plot=False):\n",
    "    \"\"\"\n",
    "    Get persistence image from the vtk file storing persistence diagram.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    diagramFile: string\n",
    "        The path of the diagram vtk file.\n",
    "    dimensions: int\n",
    "        The homology dimension.\n",
    "    plot: bool\n",
    "        If True, plot the computed persistence image.\n",
    "        \n",
    "    Returns \n",
    "    ----------\n",
    "    persImage: array\n",
    "        The numpy array storing the persistence image.\n",
    "    \"\"\"\n",
    "    num_pixels = 10\n",
    "    pdiagram = getPersDiagram(diagramFile)\n",
    "    if pdiagram.size == 0:\n",
    "        return np.zeros((num_pixels, num_pixels))\n",
    "    pdiagram3D = pdiagram.reshape(1, -1, 3)\n",
    "    \n",
    "    pimgr = gdiagrams.PersistenceImage(sigma=0.1, n_bins=num_pixels)\n",
    "    fit(pimgr, pdiagram3D)\n",
    "    persImage = pimgr.transform(pdiagram3D)\n",
    "    \n",
    "    if dimension is None: \n",
    "        if plot:\n",
    "            pimgr.plot(persImage)\n",
    "        return persImage[0]\n",
    "    \n",
    "    if dimension >= persImage.shape[1]:\n",
    "        return np.zeros((num_pixels, num_pixels))\n",
    "    \n",
    "    if plot:\n",
    "        fig = pimgr.plot(persImage, homology_dimension_idx=dimension)\n",
    "        fig.show()\n",
    "    return persImage[0][dimension]\n",
    "    \n",
    "\n",
    "persImages = []\n",
    "fileLabels = []\n",
    "for i in range(10):\n",
    "    pdiagDir = os.path.join(VTK_DIR, str(i))\n",
    "    if os.path.exists(pdiagDir):\n",
    "        files = [f for f in os.listdir(pdiagDir) if \"_pd.vtk\" in f]\n",
    "        files.sort()\n",
    "        for file in files:\n",
    "            filePath = os.path.join(pdiagDir, file)\n",
    "            persImages.append(getPersImage(filePath, 1))\n",
    "            fileLabels.append(str(i) + '/' + file)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "surprising-birth",
   "metadata": {},
   "source": [
    "Each persistence image is then vectorized and used as a high-dimensional descriptor of the input datum. To explore similarity and differences among these descriptors we use t-SNE to generate a lower dimensional embedding for such descriptors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "meaningful-while",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scipy.spatial.distance as ssdist\n",
    "from sklearn import manifold\n",
    "from sklearn.metrics import pairwise_distances\n",
    "\n",
    "def getEmbeddings(persImages):\n",
    "    \"\"\"\n",
    "    Get the embeddings from the distance matrix using different methods.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    persImage: array_like\n",
    "        The array storing persistence images of same size.\n",
    "    \n",
    "    Returns\n",
    "    ----------\n",
    "    embeddings: ndarray \n",
    "        The array containing embeddings computed with t-SNE.\n",
    "    \"\"\"\n",
    "    pers_images = np.asarray(persImages)\n",
    "    if pers_images.ndim != 3:\n",
    "        print(\"The dimension of the input array should be 3!\\n\")\n",
    "        return -1\n",
    "    \n",
    "    pers_images = pers_images.reshape(len(pers_images), -1)\n",
    "    tSNEMethod = manifold.TSNE(n_components=2, init=\"pca\", random_state=0)\n",
    "    embeddings = tSNEMethod.fit_transform(pers_images)\n",
    "    \n",
    "    return embeddings\n",
    "\n",
    "digitLabels = [f[0] for f in fileLabels]\n",
    "Y = getEmbeddings(persImages)\n",
    "# plot the scattering \n",
    "df = pd.DataFrame(data={\"x\":Y[:,0], \"y\":Y[:,1], \"digit\": digitLabels, \"file\": fileLabels})\n",
    "embeddingPlot = px.scatter(df, x=\"x\", y=\"y\", color=\"digit\", hover_data=[\"x\", \"y\", \"file\"])\n",
    "iplot(embeddingPlot)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "common-respect",
   "metadata": {},
   "source": [
    "The lower dimensional embedding provides information regarding possible groups created by using the input descriptors. In this case, since we are using descriptors based on 1-cycles only, the main difference captured by t-SNE relates to the number of cycles found in each filtration.\n",
    "\n",
    "At this point, natural questions may arise like: \"why two points are close/far away in the 2d plot\" or \"how similar the original descriptors are?\". Cycles can help answering these questions by providing an explicit representation of the homology classes that contributed to each persistence image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "experimental-wagon",
   "metadata": {},
   "source": [
    "![scaled_plot](./pictures/plot_example.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "adjustable-floor",
   "metadata": {},
   "source": [
    "The figure above shows the scaled view of the bottom right part of the scatter plot for t-SNE embeddings, where most digits are 8 with two cycles. Notice here the purple dot is associated with the file `3/18_pd.vtk` and the coral pink dot is associated with the file `6/366_pd.vtk`. To understand why they appear here, we can get the cycle information from the corresponding cycle vtk files. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "developmental-creek",
   "metadata": {},
   "outputs": [],
   "source": [
    "from plotly.subplots import make_subplots\n",
    "\n",
    "digitList = [\"3/18\", \"6/366\"]\n",
    "\n",
    "for digitPrefix in digitList:\n",
    "    pngFile = os.path.join(IMG_DIR, digitPrefix+\".png\")\n",
    "    img = io.imread(pngFile)\n",
    "\n",
    "    cycleFile = os.path.join(VTK_DIR, digitPrefix+\"_cycles.vtk\")\n",
    "    iplot(visualizeCycles(img, cycleFile))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "enabling-juvenile",
   "metadata": {},
   "source": [
    "From the images above, we can see that the digit 3 and 6 have two major cycles, which makes them accidently clustered with digit 8. We can find the similar cause for other points in the figure too."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "united-column",
   "metadata": {},
   "source": [
    "# 3. Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "rising-anime",
   "metadata": {},
   "source": [
    "\n",
    "Our apprach uses Discrete Morse Theory to encode the original chain complex by means of a Forma gradient. In practice, this allows for a more compact encoding of the information normally contained in the boundary matrix. Everything is implemented in plain C++ and integrated in the [TTK library]().\n",
    "\n",
    "The steps for computing persistent homology with our modules are the following:\n",
    "\n",
    "1. triangulate the input image (feature provided by [TTK](https://github.com/topology-tool-kit/ttk/tree/dev/core/vtk/ttkTriangulationReader))\n",
    "2. compute the Forman gradient according to the algorithm by [Robins et al., 2011](https://ieeexplore.ieee.org/document/5766002) (implemented [here](https://github.com/IuricichF/PersistenceCycles/tree/main/ttk-0.9.7/core/base/formanGradient))\n",
    "3. compute the chain complex represented by the Forman gradient (implemented [here](https://github.com/IuricichF/PersistenceCycles/blob/b68ae3ebc218ed69babeee5c1e4ac7f5a89564cd/ttk-0.9.7/core/base/fG_PersistentHomology/FG_PersistentHomology_template.h#L37))\n",
    "4. use the standard algorithm to compute persitent homology on the chain complex (implemented [here](https://github.com/IuricichF/PersistenceCycles/tree/main/ttk-0.9.7/core/base/boundaryMatrix))\n",
    "5. for each pair reconstruct the cycle (implemented [here](https://github.com/IuricichF/PersistenceCycles/blob/b68ae3ebc218ed69babeee5c1e4ac7f5a89564cd/ttk-0.9.7/core/base/fG_PersistentHomology/FG_PersistentHomology_template.h#L318))\n",
    "\n",
    "The method turns out very efficient even if we are just interested in computing persistent homology. On the larger image we tested it (a 3D image of size [500x500x100]) the computation of persistent homology takes 66.5 seconds and 1.09GB of memory using 48 threads on a desktop computer with two 3.00GHz Intel Xeon 6136 CPUs and 64GB of memory. As a comparison, [DIPHA](https://github.com/DIPHA/dipha) requires 69.4 seconds and 29.7GB on the same machine.\n",
    "\n",
    "\n",
    "Mapping information from the persistent diagram back to the original domain is a feature rarely offered by TDA packages. In part, this is due to the algorithms used to speedup persistent homology computation. Since they distrupt the information contained in the boundary matrix, it becomes impossible to reconstruct cycles.\n",
    "\n",
    "Finding the location of the simplices responsible for a birth or death is simpler task. To the best of our knowledge only [TTK](https://topology-tool-kit.github.io/index.html) and [HomCloud](https://homcloud.dev/basic-usage.en.html) provide such feature.\n",
    "\n",
    "Regarding the computation of cycles, [Eeirene](https://github.com/Eetion/Eirene.jl), a package developed in Julia, provides the computation of representative cycles when working on Vietoris-Rips filtrations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "diverse-accreditation",
   "metadata": {},
   "source": [
    "# 4. Limitations and Perspectives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "suburban-nursing",
   "metadata": {},
   "source": [
    "## Limitations of our method\n",
    "\n",
    "To build up our notebook we had to compute persistence diagrams and corresponding cycles outside of Giotto-TDA. We also needed persistence pairs to be aligned with the cycles computed.\n",
    "\n",
    "Our currenet implementation presents some limitation since it is designed to work with simplicial complexes up to dimension 3 only. This includes triangle meshes, tetrahedral meshes, or 2D and 3D images that are automatically triangulated by TTK.\n",
    "\n",
    "## Limitations of Giotto-TDA\n",
    "\n",
    "One problem we encountered wth Giotto-TDA was when computing persistence images on persistence diagrams formed by a single persistence pair.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "annual-semester",
   "metadata": {},
   "outputs": [],
   "source": [
    "exampleDiagram = np.array([[[0.1, 0.6, 1]]])\n",
    "pimgr = gdiagrams.PersistenceImage(sigma=0.01, n_bins=10)\n",
    "pimgr.fit(exampleDiagram)\n",
    "persImage = pimgr.transform(exampleDiagram)\n",
    "print(persImage)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "negative-scene",
   "metadata": {},
   "source": [
    "The root cause of the problem is in the `_bin()` function from `gtda.diagrams._utils`, and specifically the code to find the minimum and maximum persistence pair from the persistence diagram for generating the sampling slices and step sizes.\n",
    "\n",
    "```python\n",
    "def _bin(X, metric, n_bins=100, homology_dimensions=None, **kw_args):\n",
    "    ......\n",
    "    min_vals = {dim: np.min(sub_diags[dim], axis=(0, 1))\n",
    "                for dim in homology_dimensions}\n",
    "    max_vals = {dim: np.max(sub_diags[dim], axis=(0, 1))\n",
    "                for dim in homology_dimensions}\n",
    "    ......\n",
    "    samplings = {}\n",
    "    step_sizes = {}\n",
    "    for dim in homology_dimensions:\n",
    "        samplings[dim], step_sizes[dim] = np.linspace(\n",
    "            min_vals[dim], max_vals[dim], retstep=True, num=n_bins\n",
    "            )\n",
    "        \n",
    "    ......\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "previous-heater",
   "metadata": {},
   "source": [
    "One possible fix would be to add a parameter for `PersistenceImage` class which allows the range to be manually set, and then to be used in the `_bin()` function. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "nominated-compilation",
   "metadata": {},
   "source": [
    "## Perspectives\n",
    "\n",
    "\n",
    "We think it would be very useful to integrate our module in Giotto-tda. While we have not taken steps in this directions yet, the integration should not be too challenging. \n",
    "\n",
    "The step requiring the most work should be adapting the input and output produced by the main functions. Regarding the input, we should update TTK Triangulation so to let it read and triangulate a numpy array. Regarding outputs, we can simply convert persistence diagrams in the format generated by Giotto-TDA and define a new object to store cycles.\n",
    "\n",
    "Aside from adapting our implementation, we should also design visualization functions for 2-cycles in 3D. In practice, these are surfaces representing the boundary of the voids created by the filtration which should be fairly easy to achieve in Plotly."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
